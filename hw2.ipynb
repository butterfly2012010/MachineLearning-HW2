{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from pprint import pprint\n",
    "import random\n",
    "# import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理\n",
    "\n",
    "1. 將 label 撈出來\n",
    "2. 刪除 'policy_id' 和 'is_claim' 欄位\n",
    "3. 對資料集連續變數的欄位進行離散化\n",
    "4. 對資料集類別變數的部分進行 label encoding\n",
    "5. 將訓練資料隨機排序後以 8:2 的比例拆分成 train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(train_df):\n",
    "    label = train_df[\"is_claim\"]\n",
    "    train_df = train_df.drop([\"policy_id\", \"is_claim\"], axis=1)\n",
    "    # numerical feature -> categorical feature (discretize)\n",
    "    for column in train_df.columns:\n",
    "        if train_df[column].dtypes != 'O':\n",
    "            train_df[column] = pd.cut(train_df[column], 22, labels=False, duplicates='drop')\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    for column in train_df.columns:\n",
    "        if train_df[column].dtypes == 'O':\n",
    "            train_df[column] = le.fit_transform(train_df[column])\n",
    "\n",
    "\n",
    "    # train.csv -> train, validation, test\n",
    "    # split test using index suffle or index sample\n",
    "    # suffle first\n",
    "    # index = list(range(len(train_df)))\n",
    "    index = np.arange(len(train_df))\n",
    "    random.seed(1)\n",
    "    random.shuffle(index) # inplace\n",
    "    # split by proportion 8:2\n",
    "    split = np.ceil(len(train_df)*0.8).astype(int)\n",
    "    train_x = train_df.loc[index[:split],]\n",
    "    test_x = train_df.loc[index[split:]]\n",
    "    train_y = label.loc[index[:split],]\n",
    "    test_y = label.loc[index[split:]]\n",
    "    # split validation\n",
    "\n",
    "    return train_x, test_x, train_y, test_y, train_df\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "train_x, test_x, train_y, test_y, train_df = preprocessing(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "- method1 的 Naive Bayes Classifier 需要跑 48 分鐘，且 predictions 有點奇怪\n",
    "- method2 參考自 vamc-stash 的 Naive-Bayes\n",
    "    > https://github.com/vamc-stash/Naive-Bayes/blob/master/src/naive_bayes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Naive Bayes Classifier (method 1)\n",
    "# class NaiveBayesClassifier:\n",
    "#     '''\n",
    "#     P(y|X) = P(X|y) * P(y) / P(X)\n",
    "#     '''\n",
    "#     def __init__(self) -> None:\n",
    "#         pass\n",
    "\n",
    "#     def calc_prior(self, features, target):\n",
    "#         '''\n",
    "#         prior = P(class) = count(y) / n\n",
    "#         '''\n",
    "#         self.prior = (features.groupby(target).apply(lambda x: len(x)) / features.shape[0]).to_numpy()\n",
    "#         return self.prior\n",
    "\n",
    "#     def calc_likelihood(self, x):\n",
    "#         '''\n",
    "#         P(X_1|y)*...*P(X_n|y)\n",
    "#         P(X_i|y) = count(X_i, y) / count(y)\n",
    "#         '''\n",
    "#         features = list(x.columns)\n",
    "#         for feature in features:\n",
    "#             for outcome in np.unique(self.y):\n",
    "#                 n_outcome = sum(self.y == outcome)\n",
    "#                 # feat_likelihood = \n",
    "\n",
    "\n",
    "#         # ---\n",
    "#         tmp_train_x = pd.concat([self.X, self.y], axis=1)\n",
    "#         length_of_each_class = self.X.groupby(self.y, group_keys=False).apply(lambda x: len(x))\n",
    "#         self.likelihood = [] # len(self.likelihood)=n_classes\n",
    "#         for i in range(self.n_classes):\n",
    "#             count = 1\n",
    "#             for j in range(len(features)):\n",
    "#                 count *= self.X.iloc[:, j].groupby(self.y, group_keys=False).get_group(self.classes[i]).isin([features[j]]).sum()\n",
    "#                 # count *= tmp_train_x.loc[pd.Series(tmp_train_x.iloc[:, j]==features[j]) & pd.Series(tmp_train_x.iloc[:,-1]==self.classes[i])].shape[0]\n",
    "#             conditional = count / length_of_each_class[self.classes[i]]**len(features)\n",
    "#             self.likelihood.append(conditional)\n",
    "#         return self.likelihood\n",
    "\n",
    "#     def calc_posterior(self, x):\n",
    "#         '''\n",
    "#         posterior = P(class|features)\n",
    "#         likelihood = P(features|class)\n",
    "#         '''\n",
    "#         posteriors = [] # len(posteriors)=n_classes\n",
    "\n",
    "#         # calculate posterior probability for each class\n",
    "#         posteriors = np.multiply(self.prior, self.calc_likelihood(x))\n",
    "#         return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "#     def fit(self, features, target):\n",
    "#         self.X = features\n",
    "#         self.y = target\n",
    "#         self.classes = np.sort(target.unique())\n",
    "#         self.n_classes = target.nunique()\n",
    "\n",
    "#         self.calc_prior(features, target)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         preds = [self.calc_posterior(x) for x in X.to_numpy()]\n",
    "#         return preds\n",
    "        \n",
    "#     def accuracy(self, y_test, y_pred):\n",
    "#         accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "#         return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes Classifier (method 2)\n",
    "class NaiveBayesClassifier:\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\t\t\"\"\"\n",
    "\t\t\t\tAttributes:\n",
    "\t\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
    "\t\t\t\t\tclass_priors: Prior probabilities of classes \n",
    "\t\t\t\t\tpred_priors: Prior probabilities of features \n",
    "\t\t\t\t\tfeatures: All features of dataset\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tself.features = list\n",
    "\t\t\tself.likelihoods = {}\n",
    "\t\t\tself.class_priors = {}\n",
    "\t\t\tself.pred_priors = {}\n",
    "\n",
    "\t\t\tself.X_train = np.array\n",
    "\t\t\tself.y_train = np.array\n",
    "\t\t\tself.train_size = int\n",
    "\t\t\tself.num_feats = int\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\n",
    "\t\tself.features = list(X.columns)\n",
    "\t\tself.X_train = X\n",
    "\t\tself.y_train = y\n",
    "\t\tself.train_size = X.shape[0]\n",
    "\t\tself.num_feats = X.shape[1]\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tself.likelihoods[feature] = {}\n",
    "\t\t\tself.pred_priors[feature] = {}\n",
    "\n",
    "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
    "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
    "\n",
    "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t\tself.likelihoods[feature].update({str(feat_val)+'_'+str(outcome):0})\n",
    "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
    "\n",
    "\n",
    "\t\tself._calc_class_prior()\n",
    "\t\tself._calc_likelihoods()\n",
    "\t\tself._calc_predictor_prior()\n",
    "\n",
    "\t\t# print(self.likelihoods)\n",
    "\t\t# print(self.class_priors)\n",
    "\t\t# print(self.pred_priors)\n",
    "\n",
    "\tdef _calc_class_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
    "\n",
    "\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n",
    "\n",
    "\tdef _calc_likelihoods(self):\n",
    "\n",
    "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "\n",
    "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
    "\t\t\t\t\tself.likelihoods[feature][str(feat_val) + '_' + str(outcome)] = count/outcome_count\n",
    "\n",
    "\n",
    "\tdef _calc_predictor_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
    "\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\n",
    "\t\t\tfor feat_val, count in feat_vals.items():\n",
    "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n",
    "\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\n",
    "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
    "\n",
    "\t\tresults = []\n",
    "\t\tX = np.array(X)\n",
    "\n",
    "\t\tfor query in X:\n",
    "\t\t\tprobs_outcome = {}\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\tprior = self.class_priors[outcome]\n",
    "\t\t\t\tlikelihood = 1\n",
    "\t\t\t\tevidence = 1\n",
    "\n",
    "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
    "\t\t\t\t\tlikelihood *= self.likelihoods[feat][str(feat_val) + '_' + str(outcome)]\n",
    "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
    "\n",
    "\t\t\t\tposterior = (likelihood * prior) / (evidence)\n",
    "\n",
    "\t\t\t\tprobs_outcome[outcome] = posterior\n",
    "\n",
    "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
    "\t\t\tresults.append(result)\n",
    "\n",
    "\t\treturn np.array(results)\n",
    "\n",
    "\tdef calculate_accuracy(self, y_true, y_pred):\n",
    "\t\taccuracy = (y_true == y_pred).mean()\n",
    "\t\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = NaiveBayesClassifier()\n",
    "clf1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348011606076122"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf1.predict(test_x)\n",
    "# 準確率\n",
    "clf1.calculate_accuracy(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10954,     3],\n",
       "       [  761,     0]], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混淆矩陣\n",
    "confusion_matrix(test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.999552\n",
      "accuracy = 0.999232\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'18_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [71], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index,], y\u001b[39m.\u001b[39miloc[test_index,]\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m---> 10\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_test)\n\u001b[0;32m     11\u001b[0m \u001b[39m# accuracy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy = \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mcalculate_accuracy(y_test, preds)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [53], line 98\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     95\u001b[0m evidence \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m feat, feat_val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, query):\n\u001b[1;32m---> 98\u001b[0m \tlikelihood \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlikelihoods[feat][\u001b[39mstr\u001b[39;49m(feat_val) \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(outcome)]\n\u001b[0;32m     99\u001b[0m \tevidence \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_priors[feat][feat_val]\n\u001b[0;32m    101\u001b[0m posterior \u001b[39m=\u001b[39m (likelihood \u001b[39m*\u001b[39m prior) \u001b[39m/\u001b[39m (evidence)\n",
      "\u001b[1;31mKeyError\u001b[0m: '18_0'"
     ]
    }
   ],
   "source": [
    "x, y = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "kf = KFold(n_splits=3)#, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    x_train, x_test = x.iloc[train_index,], x.iloc[test_index,]\n",
    "    y_train, y_test = y.iloc[train_index,], y.iloc[test_index,]\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    print(f\"accuracy = {model.calculate_accuracy(y_test, preds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.99936\n",
      "accuracy = 0.9998933333333333\n",
      "accuracy = 0.9991466666666666\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'10_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [72], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index,], y\u001b[39m.\u001b[39miloc[test_index,]\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m---> 10\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_test)\n\u001b[0;32m     11\u001b[0m \u001b[39m# accuracy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy = \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mcalculate_accuracy(y_test, preds)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [53], line 98\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     95\u001b[0m evidence \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m feat, feat_val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, query):\n\u001b[1;32m---> 98\u001b[0m \tlikelihood \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlikelihoods[feat][\u001b[39mstr\u001b[39;49m(feat_val) \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(outcome)]\n\u001b[0;32m     99\u001b[0m \tevidence \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_priors[feat][feat_val]\n\u001b[0;32m    101\u001b[0m posterior \u001b[39m=\u001b[39m (likelihood \u001b[39m*\u001b[39m prior) \u001b[39m/\u001b[39m (evidence)\n",
      "\u001b[1;31mKeyError\u001b[0m: '10_0'"
     ]
    }
   ],
   "source": [
    "x, y = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "kf = KFold(n_splits=5)#, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    x_train, x_test = x.iloc[train_index,], x.iloc[test_index,]\n",
    "    y_train, y_test = y.iloc[train_index,], y.iloc[test_index,]\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    print(f\"accuracy = {model.calculate_accuracy(y_test, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9997866894197952\n",
      "accuracy = 0.9997866894197952\n",
      "accuracy = 0.9997866894197952\n",
      "accuracy = 1.0\n",
      "accuracy = 0.9991465756347344\n",
      "accuracy = 0.9995732878173672\n",
      "accuracy = 0.9995732878173672\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'18_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [73], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index,], y\u001b[39m.\u001b[39miloc[test_index,]\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m---> 10\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_test)\n\u001b[0;32m     11\u001b[0m \u001b[39m# accuracy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy = \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mcalculate_accuracy(y_test, preds)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [53], line 98\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     95\u001b[0m evidence \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m feat, feat_val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, query):\n\u001b[1;32m---> 98\u001b[0m \tlikelihood \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlikelihoods[feat][\u001b[39mstr\u001b[39;49m(feat_val) \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(outcome)]\n\u001b[0;32m     99\u001b[0m \tevidence \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_priors[feat][feat_val]\n\u001b[0;32m    101\u001b[0m posterior \u001b[39m=\u001b[39m (likelihood \u001b[39m*\u001b[39m prior) \u001b[39m/\u001b[39m (evidence)\n",
      "\u001b[1;31mKeyError\u001b[0m: '18_0'"
     ]
    }
   ],
   "source": [
    "x, y = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "kf = KFold(n_splits=10)#, random_state=1, shuffle=True)\n",
    "for train_index, test_index in kf.split(train_x):\n",
    "    x_train, x_test = x.iloc[train_index,], x.iloc[test_index,]\n",
    "    y_train, y_test = y.iloc[train_index,], y.iloc[test_index,]\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    # accuracy\n",
    "    print(f\"accuracy = {model.calculate_accuracy(y_test, preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "- 參考自 SebastianMantey 的 Random-Forest-from-Scratch\n",
    "    > https://github.com/SebastianMantey/Random-Forest-from-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Classifier\n",
    "class RandomForestClassifier_scratch:\n",
    "    def __init__(self) -> None:\n",
    "        # self.max_depth\n",
    "        # self.n_trees\n",
    "        pass\n",
    "\n",
    "    # bagging in #data\n",
    "    # #tree, #max-depth of each tree, etc. could be predefined\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "    # 1. Train-Test-Split\n",
    "    def train_test_split(self, df, test_size):\n",
    "        \n",
    "        if isinstance(test_size, float):\n",
    "            test_size = round(test_size * len(df))\n",
    "\n",
    "        indices = df.index.tolist()\n",
    "        test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "        test_df = df.loc[test_indices]\n",
    "        train_df = df.drop(test_indices)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "\n",
    "    # 2. Distinguish categorical and continuous features\n",
    "    def determine_type_of_feature(self, df):\n",
    "        \n",
    "        feature_types = []\n",
    "        n_unique_values_treshold = 15\n",
    "        for feature in df.columns:\n",
    "            if feature != \"is_claim\": # \"label\"\n",
    "                unique_values = df[feature].unique()\n",
    "                example_value = unique_values[0]\n",
    "\n",
    "                if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                    feature_types.append(\"categorical\")\n",
    "                else:\n",
    "                    feature_types.append(\"continuous\")\n",
    "        \n",
    "        return feature_types\n",
    "\n",
    "\n",
    "    # 3. Accuracy\n",
    "    def calculate_accuracy(self, predictions, labels):\n",
    "        predictions_correct = predictions == labels\n",
    "        accuracy = predictions_correct.mean()\n",
    "        \n",
    "        return accuracy\n",
    "    # ---------------------------------------------------------------------------------------------\n",
    "    # 1. Decision Tree helper functions \n",
    "\n",
    "    # 1.1 Data pure?\n",
    "    def check_purity(self, data):\n",
    "        \n",
    "        label_column = data[:, -1]\n",
    "        unique_classes = np.unique(label_column)\n",
    "\n",
    "        if len(unique_classes) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "    # 1.2 Classify\n",
    "    def classify_data(self, data):\n",
    "        \n",
    "        label_column = data[:, -1]\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "        index = counts_unique_classes.argmax()\n",
    "        classification = unique_classes[index]\n",
    "        \n",
    "        return classification\n",
    "\n",
    "\n",
    "    # 1.3 Potential splits?\n",
    "    def get_potential_splits(self, data, random_subspace):\n",
    "        \n",
    "        potential_splits = {}\n",
    "        _, n_columns = data.shape\n",
    "        column_indices = list(range(n_columns - 1))    # excluding the last column which is the label\n",
    "        \n",
    "        if random_subspace and random_subspace <= len(column_indices):\n",
    "            column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "        \n",
    "        for column_index in column_indices:          \n",
    "            values = data[:, column_index]\n",
    "            unique_values = np.unique(values)\n",
    "            \n",
    "            potential_splits[column_index] = unique_values\n",
    "        \n",
    "        return potential_splits\n",
    "\n",
    "\n",
    "    # 1.4 Lowest Overall Entropy?\n",
    "    def calculate_entropy(self, data):\n",
    "        \n",
    "        label_column = data[:, -1]\n",
    "        _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "        probabilities = counts / counts.sum()\n",
    "        entropy = sum(probabilities * -np.log2(probabilities))\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def calculate_overall_entropy(self, data_below, data_above):\n",
    "        \n",
    "        n = len(data_below) + len(data_above)\n",
    "        p_data_below = len(data_below) / n\n",
    "        p_data_above = len(data_above) / n\n",
    "\n",
    "        overall_entropy =  (p_data_below * self.calculate_entropy(data_below) \n",
    "                        + p_data_above * self.calculate_entropy(data_above))\n",
    "        \n",
    "        return overall_entropy\n",
    "\n",
    "\n",
    "    def determine_best_split(self, data, potential_splits):\n",
    "        \n",
    "        overall_entropy = 9999\n",
    "        for column_index in potential_splits:\n",
    "            for value in potential_splits[column_index]:\n",
    "                data_below, data_above = self.split_data(data, split_column=column_index, split_value=value)\n",
    "                current_overall_entropy = self.calculate_overall_entropy(data_below, data_above)\n",
    "                \n",
    "                if current_overall_entropy <= overall_entropy:\n",
    "                    overall_entropy = current_overall_entropy\n",
    "                    best_split_column = column_index\n",
    "                    best_split_value = value\n",
    "        \n",
    "        return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "    # 1.5 Split data\n",
    "    def split_data(self, data, split_column, split_value):\n",
    "        \n",
    "        split_column_values = data[:, split_column]\n",
    "\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            data_below = data[split_column_values <= split_value]\n",
    "            data_above = data[split_column_values >  split_value]\n",
    "        \n",
    "        # feature is categorical   \n",
    "        else:\n",
    "            data_below = data[split_column_values == split_value]\n",
    "            data_above = data[split_column_values != split_value]\n",
    "        \n",
    "        return data_below, data_above\n",
    "\n",
    "\n",
    "    # 2. Decision Tree Algorithm\n",
    "    def decision_tree_algorithm(self, df, counter=0, min_samples=2, max_depth=5, random_subspace=None):\n",
    "        \n",
    "        # data preparations\n",
    "        if counter == 0:\n",
    "            global COLUMN_HEADERS, FEATURE_TYPES\n",
    "            COLUMN_HEADERS = df.columns\n",
    "            FEATURE_TYPES = self.determine_type_of_feature(df)\n",
    "            data = df.values\n",
    "        else:\n",
    "            data = df           \n",
    "        \n",
    "        \n",
    "        # base cases\n",
    "        if (self.check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "            classification = self.classify_data(data)\n",
    "            \n",
    "            return classification\n",
    "\n",
    "        \n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "\n",
    "            # helper functions \n",
    "            potential_splits = self.get_potential_splits(data, random_subspace)\n",
    "            split_column, split_value = self.determine_best_split(data, potential_splits)\n",
    "            data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "            \n",
    "            # check for empty data\n",
    "            if len(data_below) == 0 or len(data_above) == 0:\n",
    "                classification = self.classify_data(data)\n",
    "                return classification\n",
    "            \n",
    "            # determine question\n",
    "            feature_name = COLUMN_HEADERS[split_column]\n",
    "            type_of_feature = FEATURE_TYPES[split_column]\n",
    "            if type_of_feature == \"continuous\":\n",
    "                question = \"{} <= {}\".format(feature_name, split_value)\n",
    "                \n",
    "            # feature is categorical\n",
    "            else:\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "            \n",
    "            # instantiate sub-tree\n",
    "            sub_tree = {question: []}\n",
    "            \n",
    "            # find answers (recursion)\n",
    "            yes_answer = self.decision_tree_algorithm(data_below, counter, min_samples, max_depth, random_subspace)\n",
    "            no_answer = self.decision_tree_algorithm(data_above, counter, min_samples, max_depth, random_subspace)\n",
    "            \n",
    "            # If the answers are the same, then there is no point in asking the qestion.\n",
    "            # This could happen when the data is classified even though it is not pure\n",
    "            # yet (min_samples or max_depth base case).\n",
    "            if yes_answer == no_answer:\n",
    "                sub_tree = yes_answer\n",
    "            else:\n",
    "                sub_tree[question].append(yes_answer)\n",
    "                sub_tree[question].append(no_answer)\n",
    "            \n",
    "            return sub_tree\n",
    "\n",
    "\n",
    "    # 3. Make predictions\n",
    "    # 3.1 One example\n",
    "    def predict_example(self, example, tree):\n",
    "        # if not isinstance(tree, dict): # 樹長不出來???\n",
    "        #     return tree\n",
    "            \n",
    "        question = list(tree.keys())[0]\n",
    "        feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "        # ask question\n",
    "        if comparison_operator == \"<=\":\n",
    "            if example[feature_name] <= float(value):\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "        \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            if str(example[feature_name]) == value:\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "\n",
    "        # base case\n",
    "        if not isinstance(answer, dict):\n",
    "            return answer\n",
    "        \n",
    "        # recursive part\n",
    "        else:\n",
    "            residual_tree = answer\n",
    "            return self.predict_example(example, residual_tree)\n",
    "\n",
    "        \n",
    "    # 3.2 All examples of the test data\n",
    "    def decision_tree_predictions(self, test_df, tree):\n",
    "        predictions = test_df.apply(self.predict_example, args=(tree,), axis=1)\n",
    "        return predictions\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "    def bootstrapping(self, train_df, n_bootstrap):\n",
    "        bootstrap_indices = np.random.randint(low=0, high=len(train_df), size=n_bootstrap)\n",
    "        df_bootstrapped = train_df.iloc[bootstrap_indices]\n",
    "        \n",
    "        return df_bootstrapped\n",
    "\n",
    "    def random_forest_algorithm(self, train_df, n_trees, n_bootstrap, n_features, dt_max_depth):\n",
    "        forest = []\n",
    "        for i in range(n_trees):\n",
    "            df_bootstrapped = self.bootstrapping(train_df, n_bootstrap)\n",
    "            tree = self.decision_tree_algorithm(df_bootstrapped, max_depth=dt_max_depth, random_subspace=n_features)\n",
    "            forest.append(tree)\n",
    "\n",
    "        return forest\n",
    "\n",
    "    def random_forest_predictions(self, test_df, forest):\n",
    "        df_predictions = {}\n",
    "        for i in range(len(forest)):\n",
    "            column_name = \"tree_{}\".format(i)\n",
    "            predictions = self.decision_tree_predictions(test_df, tree=forest[i])\n",
    "            df_predictions[column_name] = predictions\n",
    "\n",
    "        df_predictions = pd.DataFrame(df_predictions)\n",
    "        random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
    "        \n",
    "        return random_forest_predictions\n",
    "\n",
    "# ===================================================================================================\n",
    "# forest = random_forest_algorithm(train_df, n_trees=4, n_bootstrap=800, n_features=2, dt_max_depth=4)\n",
    "# predictions = random_forest_predictions(test_df, forest)\n",
    "# accuracy = calculate_accuracy(predictions, test_df.label)\n",
    "\n",
    "# print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################### 舊的 (method1) Naive Bayes Classifier 部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf1 = NaiveBayesClassifier()\n",
    "# clf1.calc_prior(train_x, train_y)\n",
    "# clf1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# preds = clf1.predict(test_x)\n",
    "# print(f\"--- {time.time() - start_time} sec ---\")\n",
    "# np.save(\"./output/predictions1.npy\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9350571769926609\n",
      "Confusion = \n",
      "[[10957     0]\n",
      " [  761     0]]\n"
     ]
    }
   ],
   "source": [
    "# preds = np.load(\"./output/predictions1.npy\")\n",
    "# accuracy = clf1.accuracy(test_y, preds)\n",
    "# print(\"Accuracy = {}\".format(accuracy))\n",
    "\n",
    "# confusion = confusion_matrix(test_y, preds)\n",
    "# print(\"Confusion = \")\n",
    "# print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([train_df, pd.concat([train_y, test_y])], axis=1)\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理一下放入隨機森林模型的 data 格式\n",
    "train_x_y = pd.concat([train_x, train_y], axis=1)\n",
    "test_x_y = pd.concat([test_x, test_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier_scratch()\n",
    "# forest = clf2.random_forest_algorithm(train_df, n_trees=4, n_bootstrap=train_df.shape[0], n_features=8, dt_max_depth=8)\n",
    "forest = clf2.random_forest_algorithm(train_x_y, n_trees=10, n_bootstrap=train_x_y.shape[0]//2, n_features=8, dt_max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'population_density = 10': [{'policy_tenure <= 9': [0,\n",
      "                                                      {'engine_type = 7': [0,\n",
      "                                                                           {'is_day_night_rear_view_mirror = 1': [0,\n",
      "                                                                                                                  {'segment = 0': [0,\n",
      "                                                                                                                                   {'fuel_type = 2': [{'age_of_policyholder <= 5': [0,\n",
      "                                                                                                                                                                                    {'area_cluster <= 3': [1,\n",
      "                                                                                                                                                                                                           0]}]},\n",
      "                                                                                                                                                      0]}]}]}]}]},\n",
      "                              {'displacement = 0': [0,\n",
      "                                                    {'width = 6': [{'age_of_policyholder <= 16': [0,\n",
      "                                                                                                  {'policy_tenure <= 4': [{'population_density = 2': [0,\n",
      "                                                                                                                                                      1]},\n",
      "                                                                                                                          1]}]},\n",
      "                                                                   {'age_of_car = 3': [0,\n",
      "                                                                                       {'max_torque = 2': [{'population_density = 3': [1,\n",
      "                                                                                                                                       0]},\n",
      "                                                                                                           0]}]}]}]}]},\n",
      " {'is_central_locking = 1': [{'model = 10': [0,\n",
      "                                             {'model = 8': [{'area_cluster <= 4': [{'age_of_car = 6': [1,\n",
      "                                                                                                       0]},\n",
      "                                                                                   0]},\n",
      "                                                            0]}]},\n",
      "                             0]},\n",
      " {'policy_tenure <= 9': [0,\n",
      "                         {'turning_radius = 12': [{'age_of_policyholder <= 13': [0,\n",
      "                                                                                 {'population_density = 2': [1,\n",
      "                                                                                                             0]}]},\n",
      "                                                  {'engine_type = 2': [{'age_of_car = 4': [1,\n",
      "                                                                                           0]},\n",
      "                                                                       0]}]}]},\n",
      " {'age_of_policyholder <= 15': [{'width = 18': [0,\n",
      "                                                {'is_rear_window_defogger = 1': [{'population_density = 21': [0,\n",
      "                                                                                                              {'max_power = 8': [0,\n",
      "                                                                                                                                 {'population_density = 10': [{'max_torque = 1': [{'age_of_policyholder <= 6': [0,\n",
      "                                                                                                                                                                                                                1]},\n",
      "                                                                                                                                                                                  0]},\n",
      "                                                                                                                                                              0]}]}]},\n",
      "                                                                                 {'length = 5': [0,\n",
      "                                                                                                 {'area_cluster <= 4': [{'age_of_car = 1': [0,\n",
      "                                                                                                                                            {'max_torque = 0': [0,\n",
      "                                                                                                                                                                {'age_of_car = 4': [1,\n",
      "                                                                                                                                                                                    0]}]}]},\n",
      "                                                                                                                        0]}]}]}]},\n",
      "                                {'segment = 1': [{'area_cluster <= 11': [1,\n",
      "                                                                         {'policy_tenure <= 16': [0,\n",
      "                                                                                                  1]}]},\n",
      "                                                 {'policy_tenure <= 2': [0,\n",
      "                                                                         {'area_cluster <= 1': [{'displacement = 12': [{'policy_tenure <= 15': [1,\n",
      "                                                                                                                                                0]},\n",
      "                                                                                                                       1]},\n",
      "                                                                                                {'turning_radius = 21': [0,\n",
      "                                                                                                                         {'max_torque = 1': [1,\n",
      "                                                                                                                                             0]}]}]}]}]}]},\n",
      " {'age_of_policyholder <= 14': [0,\n",
      "                                {'population_density = 8': [0,\n",
      "                                                            {'displacement = 12': [0,\n",
      "                                                                                   {'is_rear_window_washer = 1': [0,\n",
      "                                                                                                                  {'displacement = 6': [{'population_density = 21': [1,\n",
      "                                                                                                                                                                     {'age_of_policyholder <= 17': [0,\n",
      "                                                                                                                                                                                                    1]}]},\n",
      "                                                                                                                                        {'policy_tenure <= 17': [0,\n",
      "                                                                                                                                                                 1]}]}]}]}]}]},\n",
      " {'age_of_policyholder <= 3': [{'make = 0': [{'age_of_car = 7': [1, 0]}, 0]},\n",
      "                               {'policy_tenure <= 8': [{'turning_radius = 9': [{'height = 3': [0,\n",
      "                                                                                               {'policy_tenure <= 3': [0,\n",
      "                                                                                                                       {'population_density = 1': [{'age_of_policyholder <= 8': [0,\n",
      "                                                                                                                                                                                 1]},\n",
      "                                                                                                                                                   0]}]}]},\n",
      "                                                                               0]},\n",
      "                                                       {'is_esc = 1': [{'max_torque = 0': [{'model = 8': [0,\n",
      "                                                                                                          {'population_density = 6': [1,\n",
      "                                                                                                                                      0]}]},\n",
      "                                                                                           0]},\n",
      "                                                                       0]}]}]},\n",
      " {'engine_type = 4': [0,\n",
      "                      {'age_of_policyholder <= 15': [0,\n",
      "                                                     {'age_of_policyholder <= 17': [{'length = 5': [1,\n",
      "                                                                                                    {'population_density = 1': [{'max_power = 6': [0,\n",
      "                                                                                                                                                   {'max_power = 1': [1,\n",
      "                                                                                                                                                                      {'policy_tenure <= 6': [1,\n",
      "                                                                                                                                                                                              0]}]}]},\n",
      "                                                                                                                                {'is_brake_assist = 1': [{'ncap_rating = 0': [0,\n",
      "                                                                                                                                                                              {'area_cluster <= 3': [1,\n",
      "                                                                                                                                                                                                     0]}]},\n",
      "                                                                                                                                                         0]}]}]},\n",
      "                                                                                    {'population_density = 5': [{'height = 3': [1,\n",
      "                                                                                                                                0]},\n",
      "                                                                                                                0]}]}]}]},\n",
      " {'policy_tenure <= 5': [0,\n",
      "                         {'max_power = 7': [0,\n",
      "                                            {'steering_type = 2': [{'population_density = 8': [{'segment = 0': [0,\n",
      "                                                                                                                {'width = 21': [{'age_of_policyholder <= 7': [0,\n",
      "                                                                                                                                                              1]},\n",
      "                                                                                                                                0]}]},\n",
      "                                                                                               0]},\n",
      "                                                                   {'height = 0': [0,\n",
      "                                                                                   {'engine_type = 8': [0,\n",
      "                                                                                                        {'age_of_car = 3': [{'population_density = 19': [{'height = 21': [1,\n",
      "                                                                                                                                                                          0]},\n",
      "                                                                                                                                                         0]},\n",
      "                                                                                                                            0]}]}]}]}]}]},\n",
      " {'max_power = 6': [{'is_rear_window_washer = 1': [{'age_of_car = 3': [0,\n",
      "                                                                       {'age_of_car = 7': [1,\n",
      "                                                                                           0]}]},\n",
      "                                                   0]},\n",
      "                    {'age_of_car = 3': [{'is_parking_camera = 1': [0,\n",
      "                                                                   {'steering_type = 2': [{'age_of_policyholder <= 0': [0,\n",
      "                                                                                                                        {'segment = 1': [0,\n",
      "                                                                                                                                         {'population_density = 10': [{'policy_tenure <= 17': [0,\n",
      "                                                                                                                                                                                               1]},\n",
      "                                                                                                                                                                      0]}]}]},\n",
      "                                                                                          {'area_cluster <= 3': [0,\n",
      "                                                                                                                 {'age_of_policyholder <= 1': [0,\n",
      "                                                                                                                                               {'area_cluster <= 4': [{'max_power = 7': [0,\n",
      "                                                                                                                                                                                         1]},\n",
      "                                                                                                                                                                      0]}]}]}]}]},\n",
      "                                        0]}]},\n",
      " {'ncap_rating = 0': [{'is_central_locking = 1': [0,\n",
      "                                                  {'cylinder = 21': [{'population_density = 19': [{'age_of_car = 3': [1,\n",
      "                                                                                                                      0]},\n",
      "                                                                                                  0]},\n",
      "                                                                     0]}]},\n",
      "                      {'segment = 2': [0,\n",
      "                                       {'policy_tenure <= 9': [{'max_power = 8': [0,\n",
      "                                                                                  {'policy_tenure <= 1': [0,\n",
      "                                                                                                          {'age_of_policyholder <= 1': [0,\n",
      "                                                                                                                                        {'age_of_policyholder <= 15': [0,\n",
      "                                                                                                                                                                       {'policy_tenure <= 5': [1,\n",
      "                                                                                                                                                                                               0]}]}]}]}]},\n",
      "                                                               {'age_of_policyholder <= 8': [0,\n",
      "                                                                                             {'area_cluster <= 20': [0,\n",
      "                                                                                                                     {'age_of_policyholder <= 10': [{'policy_tenure <= 11': [1,\n",
      "                                                                                                                                                                             0]},\n",
      "                                                                                                                                                    0]}]}]}]}]}]}]\n"
     ]
    }
   ],
   "source": [
    "# forest\n",
    "pprint(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'population_density = 10': [{'policy_tenure <= 9': [0,\n",
      "                                                     {'engine_type = 7': [0,\n",
      "                                                                          {'is_day_night_rear_view_mirror = 1': [0,\n",
      "                                                                                                                 {'segment = 0': [0,\n",
      "                                                                                                                                  {'fuel_type = 2': [{'age_of_policyholder <= 5': [0,\n",
      "                                                                                                                                                                                   {'area_cluster <= 3': [1,\n",
      "                                                                                                                                                                                                          0]}]},\n",
      "                                                                                                                                                     0]}]}]}]}]},\n",
      "                             {'displacement = 0': [0,\n",
      "                                                   {'width = 6': [{'age_of_policyholder <= 16': [0,\n",
      "                                                                                                 {'policy_tenure <= 4': [{'population_density = 2': [0,\n",
      "                                                                                                                                                     1]},\n",
      "                                                                                                                         1]}]},\n",
      "                                                                  {'age_of_car = 3': [0,\n",
      "                                                                                      {'max_torque = 2': [{'population_density = 3': [1,\n",
      "                                                                                                                                      0]},\n",
      "                                                                                                          0]}]}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "# one tree of forest\n",
    "pprint(forest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9350571769926609\n",
      "Confusion = \n",
      "[[10957     0]\n",
      " [  761     0]]\n"
     ]
    }
   ],
   "source": [
    "preds = clf2.random_forest_predictions(test_x_y, forest)\n",
    "# accuracy = clf2.calculate_accuracy(preds, test_y)\n",
    "accuracy = clf2.calculate_accuracy(preds, test_x_y.iloc[:, -1])\n",
    "print(\"Accuracy = {}\".format(accuracy))\n",
    "# confusion = confusion_matrix(test_y, preds)\n",
    "confusion = confusion_matrix(test_x_y.iloc[:, -1], preds)\n",
    "print(\"Confusion = \")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier (scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learn\n",
    "# Random Forest Classifier\n",
    "clf3 = RandomForestClassifier(criterion='entropy', random_state=1)\n",
    "clf3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9202935654548557\n"
     ]
    }
   ],
   "source": [
    "preds = clf3.predict(test_x)\n",
    "# accuracy\n",
    "accuracy = clf3.score(test_x, test_y)\n",
    "print(f\"accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10771,   186],\n",
       "       [  748,    13]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.919168   0.923392   0.92197901]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='entropy', random_state=1)\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91968    0.92053333 0.92469333 0.92181333 0.92361852]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='entropy', random_state=1)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92150171 0.91702218 0.91467577 0.9253413  0.92404523 0.92425859\n",
      " 0.92063153 0.92063153 0.92575208 0.92404523]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion='entropy', random_state=1)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, DMatrix, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instance\n",
    "bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "# fit model\n",
    "bst.fit(train_x, train_y)\n",
    "# make predictions\n",
    "preds = bst.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9350571769926609\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(f\"accuracy = {accuracy_score(test_y, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10957,     0],\n",
       "       [  761,     0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.933056   0.938816   0.93554788]\n"
     ]
    }
   ],
   "source": [
    "bst = XGBClassifier()\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "results = cross_val_score(bst, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93301333 0.93493333 0.93738667 0.93653333 0.93759334]\n"
     ]
    }
   ],
   "source": [
    "bst = XGBClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "results = cross_val_score(bst, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93302048 0.93280717 0.93174061 0.93856655 0.93770002 0.93705995\n",
      " 0.93770002 0.93577982 0.93791338 0.93705995]\n"
     ]
    }
   ],
   "source": [
    "bst = XGBClassifier()\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_val_score(bst, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (c:\\Program Files\\Python311\\Lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcatboost\u001b[39;00m \u001b[39mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      3\u001b[0m clf4 \u001b[39m=\u001b[39m CatBoostClassifier(random_seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m                          loss_function\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRMSE\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                          eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRMSE\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                          use_best_model\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m clf4\u001b[39m.\u001b[39mfit(train_x, train_y)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\catboost\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatboostError, cv  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwidget\u001b[39;00m \u001b[39mimport\u001b[39;00m CatboostIpythonWidget  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\catboost\\core.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mimport\u001b[39;00m iteritems, string_types\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterable, Sequence, Mapping, MutableMapping\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (c:\\Program Files\\Python311\\Lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier # python 3.10 後 Iterable 從 collections 拿掉了，因此有 error\n",
    "                                        # https://stackoverflow.com/questions/72032032/importerror-cannot-import-name-iterable-from-collections-in-python\n",
    "\n",
    "clf4 = CatBoostClassifier(random_seed=1,\n",
    "                         loss_function='RMSE',\n",
    "                         eval_metric='RMSE',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf4.fit(train_x, train_y)\n",
    "preds = clf4.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "print(f\"accuracy = {accuracy_score(test_y, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf5 = LGBMClassifier(objective = 'binary', \n",
    "                            learning_rate = 0.05, \n",
    "                            n_estimators = 100, \n",
    "                            random_state=1)\n",
    "clf5.fit(train_x, train_y)\n",
    "preds = clf5.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9350571769926609\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(f\"accuracy = {accuracy_score(test_y, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10957,     0],\n",
       "       [  761,     0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93344    0.9392     0.93612391]\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 0.93514667 0.93792    0.93728    0.93770002]\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93366041 0.93323379 0.93174061 0.93877986 0.93834009 0.93748667\n",
      " 0.93834009 0.93599317 0.93812673 0.93727331]\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "results = cross_val_score(model, train_x, train_y, cv=kfold)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
